{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 2: Decision trees and machine learning fundamentals \n",
    "### Associated lectures: [Lectures 2 and 3](https://github.com/UBC-CS/cpsc330-2023W1/tree/main/lectures) \n",
    "\n",
    "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Instructions\n",
    "rubric={points}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2023W1/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "You are welcome to broadly discuss questions with your classmates but your final answers must be your own. **We are not allowing group submission for this homework assignment.**  \n",
    "\n",
    "**Important**: In this assignment we are using autograder so that you can get feedback on your solutions. For the autograder to work, you need to install `otter` in the course environment as follows. \n",
    "\n",
    "1. Go to the command line/terminal.\n",
    "2. Activate the course conda environment and install otter-grader using the following commands.\n",
    "\n",
    "    ```\n",
    "    conda activate cpsc330\n",
    "    pip install otter-grader\n",
    "    ```\n",
    "\n",
    "The cell at the top of the notebook will throw an error if you do not install `otter-grader`. Once you are done with the assignment follow the instructions below before the submission. \n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Make sure to access Gradescope via [Canvas](https://canvas.ubc.ca/courses/123439). Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. \n",
    "4. Make sure that the plots and output are rendered properly in your submitted file. If the .ipynb file is too big and doesn't render on Gradescope, also upload a pdf or html in addition to the .ipynb so that the TAs can view your submission on Gradescope.\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the data set\n",
    " \n",
    "For the rest of the lab you'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset. The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features). \n",
    "\n",
    "This dataset is publicly available on Kaggle, and you will have to download it yourself. Follow the steps below to get the data CSV. \n",
    "\n",
    "1. If you do not have an account with [Kaggle](https://www.kaggle.com/), you will first need to create one (it's free).\n",
    "2. Login to your account and [download](https://www.kaggle.com/geomack/spotifyclassification/download) the dataset.\n",
    "3. Unzip the data file if needed, then rename it to `spotify.csv`, and move it under the `data` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4d478b6cdc9bf88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Loading the data\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Read in the data CSV and store it as a pandas dataframe named `spotify_df`. The first column of the .csv file should be set as the index.\n",
    "\n",
    "> Make sure you have put the data CSV as `spotify.csv` under the data directory (data/spotify.csv). When you read the data file, use this relative path for the autograder to work properly on Gradescope. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4f3f14b59fd7e6b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spotify_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.2 Number of training and test examples\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Run the following line of code to split the data. How many training and test examples do we have? Store them in variables `n_train_samples` and `n_test_samples`, respectively.  \n",
    "\n",
    "> Note: we are setting the `random_state` so that everyone has the same split on their assignments. This will make it easier for the TAs to grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(spotify_df, test_size=0.2, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Please provide numeric values\n",
    "n_train_samples = None\n",
    "n_test_samples = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### 1.3 `describe()` method\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Store the output of describe() on the training split in spotify_summary variable below and display the summary statistics. By default, this function will compute some summary statistics of the numeric columns.\n",
    "2. Which feature has the smallest range? Store the feature name as a string in the `smallest_range_feature` variable below.\n",
    "\n",
    "> Hint: You can subtract the min value from the max value of the column to get the range.\n",
    "\n",
    "> Note that `describe` returns another DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spotify_summary = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "smallest_range_feature = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b33320bcf667584a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.4 Plotting histograms \n",
    "rubric={points}\n",
    "\n",
    "The starter code below produces histograms for the `loudness` feature which shows the distribution of the feature values in the training set, separated for positive (target=1, i.e., user liked the song) and negative (target=0, i.e., user disliked the song) examples. There are two different histograms, one for target = 0 and one for target = 1, and they are overlaid on top of each other. The histogram shows that extremely quiet songs tend to be disliked (more blue bars than orange on the left) and very loud songs also tend to be disliked (more blue than orange on the far right).\n",
    "\n",
    "> Note: I am using pandas plotting here. You can also use matplotlib if you wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "feat = \"loudness\"\n",
    "ax = train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True)\n",
    "plt.xlabel(feat)\n",
    "plt.title(\"Histogram of \" + feat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Your tasks:**\n",
    "\n",
    "Create histograms for the following features in the order below.\n",
    "- acousticness\n",
    "- danceability\n",
    "- tempo\n",
    "- energy\n",
    "- valence\n",
    "\n",
    "> To adhere to the [DRY (Don't Repeat Yourself)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle, make sure you use a `for` loop for your plotting, rather than repeating the plotting code 4 times. For this to work, I used `plt.show()` at the end of your loop, which draws the figure and resets the canvas for your next plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {
     "tags": [
      "otter_ignore"
     ]
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96fe8a8084b1ca46",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.5 Identical histograms\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Let's say that, for a particular feature, the histograms of that feature are identical for the two target classes. Does that mean the feature is not useful for predicting the target class? Briefly explain your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86f9e0c649669daf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 1.6 Which columns to include? \n",
    "rubric={reasoning}\n",
    "\n",
    "Note that the dataset includes two text features labeled `song_title` and `artist`.\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Do you think these features could be useful in predicting whether the user liked the song or not? Why or why not? \n",
    "2. Would there be any difficulty in using these features, in the form they are, in your model? Briefly explain.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.6\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1440876fbc49ead5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2: Using sklearn to build a decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Recall that in machine learning what we care about is generalization; we want to build models that generalize well on unseen examples. One way to approximate generalization error is by splitting the data into train and test splits, building and tuning the model only using the train split, and carrying out the final assessment on the test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706403e72adade4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Separating `X` and `y`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Separate `X` and `y` from `train_df` and `test_df` and store them as `X_train`, `y_train`, `X_test`, `y_test`, respectively. Drop the `song_title` and `artist` columns for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.2 Training a baseline model `DummyClassifier`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Train a baseline model. In particular, carry out 10-fold cross-validation using `DummyClassifier` with `random_state=123`. Store the mean cross-validation score in the `dummy_score` variable below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dummy_score = None\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-706403e72adade4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Training a decision tree mode with default hyperparameters \n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `DecisionTreeClassifier` with `random_state=123` and store it in a variable called `spotify_tree`.\n",
    "2. Fit the the decision tree classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "spotify_tree = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-43ac6f91bc3bd9da",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Predicting using the trained model\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Use the `predict` method to predict the class of the first example in your `X_train` and store the prediction in a variable called `pred` and compare it with the \"true\" class from `y_train`.   \n",
    "\n",
    "> Hint: you can grab the first example with `X_train.iloc[[0]]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "pred = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.5 `cross_val_score`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the `cross_val_score` function on your training set to compute the 10-fold cross-validation accuracy of your tree. Store the mean cross-validation accuracy in a variable called `mean_cv_score`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mean_cv_score = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2.6 `cross_validate`\n",
    "rubric={autograde}\n",
    "\n",
    "The above is useful, but we would like to see the training accuracy as well. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Compute the 10-fold cross-validation again but this time using the `cross_validate` function with `return_train_score=True` and save the results in a variable called `scores_df` as a pandas dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.6\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "scores_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.7 Examining subs-cores\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Inspect the 10 sub-scores from the 10 folds of cross-validation. How does this inform the trustworthiness of your mean cross-validation score?\n",
    "2. Do you see a significant difference between the training scores and the cross-validation scores? Briefly explain in 1 to 2 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2.7\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4150979c1845a18c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3: Hyperparameters \n",
    "\n",
    "In this exercise, you'll experiment with the `max_depth` hyperparameter of the decision tree classifier. See the [`DecisionTreeClassifier` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.1 Train and cross-validation accuracies \n",
    "rubric={autograde}\n",
    "\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore the `max_depth` hyperparameter. Run 10-fold cross-validation for trees with the following values of `max_depth`: `np.arange(1, 25, 2)`. Set the `random_state` of `DecisionTreeClassifier` to 123 in each case for reproducibility. \n",
    "2. For each `max_depth`, get both the mean train accuracy and the mean cross-validation accuracy. Store your results in the `results_df` dataframe.\n",
    "\n",
    "> Note: generally speaking (for all assignments) you are welcome to copy/paste code directly from the lecture notes, though I ask that you add a small citation (e.g. \"Adapted from lecture 2\") if you do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1, 25, 2)\n",
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-333a326eff884930",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "results_df = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.2 Visualization \n",
    "rubric={points}\n",
    "\n",
    "1. Make a plot with `max_depth` on the *x*-axis and the train and cross-validation accuracies on the *y*-axis. That is, your plot should have two curves, one for train and one for cross-validation. Save the plot to `max_depth_plot`.\n",
    "\n",
    "**Ensure your plot `max_depth_plot` includes the following:**\n",
    "\n",
    "1. Both the train accuracy and the cross-validation accuracy are included in the plot.\n",
    "2. Include a legend to specify which is which. \n",
    "3. The provided `max_depth` values are used.\n",
    "4. The x-axis and y-axis have reasonable names.\n",
    "5. The data points are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_depth_plot: the figure plotted for this exercise\n",
    "max_depth_plot = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert not max_depth_plot is None, \"Are you storing the plot in a variable?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.3 `max_depth` and the fundamental tradeoff\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Discuss how changing the `max_depth` hyperparameter affects the training and cross-validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.4 Picking a reasonable value for `max_depth`\n",
    "rubric={autograde}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "From these results, what value for max_depth would you pick as the optimal value? Store it in the variable called `best_max_depth` below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "best_max_depth = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3.5 Final assessment on the test set\n",
    "rubric={autograde}\n",
    "\n",
    "Remember the test set you created way back at the beginning of this assignment? Let's use it now to see if our cross-validation score from the previous exercise is trustworthy. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a decision tree model `best_model` using the `best_max_depth` you chose in the previous exercise. \n",
    "2. Fit the `best_model` on the _entire training set_ (`X_train` and `y_train`). \n",
    "2. Compute the test score (on `X_test` and `y_test`) and store it in a variable called `test_score` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "best_model = None\n",
    "test_score = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3.6 Analysis\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. How do the test scores compare to the cross-validation scores? Briefly discuss.\n",
    "2. Why can't you simply pick the value of `max_depth` that gives the best accuracy on the training data? (Answer in maximum 2 to 3 sentences.)\n",
    "3. Do you think that the `max_depth` you chose would generalize to other \"spotify\" datasets (i.e., data on other spotify users)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_3.6\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 4: Conceptual questions\n",
    "rubric={points}\n",
    "\n",
    "Consider the dataset below, which has $6$ examples and $2$ features:\n",
    "\n",
    "$$X = \\begin{bmatrix}5 & 2\\\\4 & 3\\\\  2 & 2\\\\ 10 & 10\\\\ 9 & -1\\\\ 9& 9\\end{bmatrix}, \\quad y = \\begin{bmatrix}-1\\\\-1\\\\+1\\\\+1\\\\+1\\\\+1\\end{bmatrix}.$$\n",
    "\n",
    "1. Say we fit a decision stump (depth 1 decision tree) and the first split is on the first feature (left column) being less than 5.5. What would we predict in the \"true\" and \"false\" cases here?\n",
    "2. What training accuracy would the above stump get on this data set?\n",
    "3. Can we obtain 100% accuracy with a single decision stump in this particular example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before submitting your assignment, please make sure you have followed all the instructions in the Submission Instructions section at the top. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Congratulations on working with your first machine learning model! Well done 👏👏!\n",
    "\n",
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "cpsc330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_df, pd.DataFrame), \"The DataFrame is not loaded correctly\"\n>>> assert spotify_df.shape == (2017, 16), \"The DataFrame has the wrong shape\"\n>>> assert np.isclose(spotify_df.valence.sum(), 1002.08), \"The DataFrame is not loaded correctly\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (not spotify_df.columns[0] != \"acousticness\"), \"Perhaps you haven't set the first column as an index column\"\n>>> assert spotify_df.index.dtype == \"int64\", \"Your index dtype is incorrect\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not n_train_samples is None, \"n_train_samples not set\"\n>>> assert not n_test_samples is None, \"n_test_samples not set.\"\n>>> assert (sha1(str(n_train_samples).encode(\"utf8\")).hexdigest() == \"2a7bcf3804dc71895222bdd5f95e64444ce51654\"), \"n_train_samples is not set correctly.\"\n>>> assert (sha1(str(n_test_samples).encode(\"utf8\")).hexdigest() == \"c35a9fc52bb556c79f8fa540df587a2bf465b940\"), \"n_test_samples is not set correctly.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3": {
     "name": "q1.3",
     "points": [
      1,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_summary, pd.DataFrame), \"Are you storing the dataframe in spotify_summary variable?\"\n>>> assert spotify_summary.shape == (8, 14), \"The spotify_summary dataframe appears to be incorrect.\"\n>>> assert np.isclose(round(spotify_summary.iloc[2][\"energy\"], 3), 0.207), \"The spotify_summary dataframe appears to be incorrect.\"\n>>> assert [round(x, 2) for x in sorted(list(spotify_summary[\"mode\"]))] == [0.00,0.00,0.49,0.62,1.00,1.00,1.00,1613.00], \"The spotify_summary dataframe appears to be incorrect.\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not smallest_range_feature is None, \"Are you using the provided variable?\"\n>>> assert (sha1(str(smallest_range_feature.lower()).encode(\"utf8\")).hexdigest() == \"1262c095e16fc4e725252b8c38f39a0ca5d1b849\"), \"Please use the exact column/feature name\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(X_train, pd.DataFrame), \"X_train is not created correctly\"\n>>> assert isinstance(y_train, pd.Series), \"y_train is not created correctly\"\n>>> assert isinstance(X_test, pd.DataFrame), \"X_test is not created correctly\"\n>>> assert isinstance(y_test, pd.Series), \"y_test is not created correctly\"\n>>> assert X_train.shape == (1613, 13), \"X_train has the wrong shape\"\n>>> assert X_test.shape == (404, 13), \"X_test has the wrong shape\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not dummy_score is None, \"Are you using the provided variable?\"\n>>> assert (sha1(str(round(dummy_score, 3)).encode(\"utf8\")).hexdigest() == \"1f27de034f09060e61929c663077d8c3d7a9d167\"), \"DummyClassifier score seems incorrect\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(spotify_tree, DecisionTreeClassifier), \"DecisionTreeClassifier was not created properly\"\n>>> assert (spotify_tree.get_params().get(\"random_state\") == 123), \"Please set the random state to 123\"\n>>> assert spotify_tree.get_depth() in range(16, 20, 1), \"DecisionTreeClassifier was not fitted properly\"\n>>> assert spotify_tree.get_n_leaves() in range(260, 270, 1), \"DecisionTreeClassifier was not fitted properly\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(pred).encode('utf8')).hexdigest() == '356a192b7913b04c54574d18c28d46e6395428ab', \"The prediction is incorrect and does not match the corresponding class in y_train\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(round(mean_cv_score, 2)).encode('utf8')).hexdigest() == 'b8b6652dcb7a26237b0e0e7dbe9192b40fee1937', \"mean_cv_score is not computed correctly\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.6": {
     "name": "q2.6",
     "points": [
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(scores_df, pd.DataFrame), \"scores_df should be a DataFrame\"\n>>> assert len(scores_df) == 10, \"Please check parameters of `cross_validate`\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert \"test_score\" in scores_df.columns, \"Your test scores are incorrect\"\n>>> assert sha1(str(round(scores_df[\"test_score\"].mean(), 2)).encode('utf8')).hexdigest() == 'b8b6652dcb7a26237b0e0e7dbe9192b40fee1937', \"Your test scores are incorrect\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert \"train_score\" in scores_df.columns, \"Your train scores are incorrect\"\n>>> assert sha1(str(round(scores_df[\"train_score\"].mean(), 2)).encode('utf8')).hexdigest() == 'e8dc057d3346e56aed7cf252185dbe1fa6454411', \"Your train scores are incorrect\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": [
      5
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert X_train.shape == (1613, 13), \"Shape of X_train is incorrect\"\n>>> assert y_train.shape == (1613,), \"Shape of y_train is incorrect\"\n>>> assert X_test.shape == (404, 13), \"Shape of X_test is incorrect\"\n>>> assert y_test.shape == (404,), \"Shape of y_test is incorrect\"\n>>> \n>>> assert (round(X_train.iloc[123][\"loudness\"], 2) == -2.42), \"Are you using the correct X_train, y_train, X_test, y_test?\"\n>>> assert (round(y_train.iloc[123], 2) == 0.00), \"Are you using the correct X_train, y_train, X_test, y_test?\"\n>>> assert (round(X_test.iloc[234][\"valence\"], 2) == 0.13), \"Are you using the correct X_train, y_train, X_test, y_test?\"\n>>> assert (round(y_test.iloc[45], 2) == 1.00), \"Are you using the correct X_train, y_train, X_test, y_test?\"\n>>> assert (results_df.shape[0] == 12), \"Are you creating results_df correctly?\"\n>>> assert (results_df.shape[1] in [2, 3]), \"Are you creating results_df correctly?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.4": {
     "name": "q3.4",
     "points": [
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not best_max_depth is None, \"Please use the provided variable\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert (sha1(str(best_max_depth).encode(\"utf8\")).hexdigest()) == \"902ba3cda1883801594b6e1b452790cc53948fda\", \"Incorrect value for best_max_depth\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5": {
     "name": "q3.5",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not test_score is None, \"Please use the provided variable\"\n>>> model_sol = DecisionTreeClassifier(max_depth=best_max_depth).fit(X_train, y_train)\n>>> test_score_sol = model_sol.score(X_test, y_test)\n>>> assert np.isclose(test_score, test_score_sol, atol=0.02)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "01a99afb195f98bb02f5f6140981f0a7ac9be086d08c6d08f7c825fb9196b5aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
